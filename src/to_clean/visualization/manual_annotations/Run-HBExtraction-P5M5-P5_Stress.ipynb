{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4859592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pathlib\n",
    "import sys\n",
    "import git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65d5a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbenesch\\.conda\\envs\\stress-requirements\\lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "code_paths = {}\n",
    "code_paths[\"repo_name\"] = \"p5-stress-classifier\"\n",
    "\n",
    "code_paths[\"repo_path\"] = os.getcwd()\n",
    "base_dir = os.path.basename(code_paths[\"repo_path\"])\n",
    "while base_dir != code_paths[\"repo_name\"]:\n",
    "    code_paths[\"repo_path\"] = os.path.dirname(os.path.abspath(code_paths[\"repo_path\"]))\n",
    "    base_dir = os.path.basename(code_paths[\"repo_path\"])\n",
    "\n",
    "package_dir = pathlib.Path(code_paths[\"repo_path\"], \"src\")\n",
    "sys.path.append(str(package_dir))\n",
    "from stresspred import (\n",
    "    peak_time_to_rri,\n",
    "    P5_StressDataLoader,\n",
    "    timestamp_to_samp,\n",
    "    resample_nonuniform,\n",
    "    code_paths,\n",
    "    timestamps_to_audacity_txt,\n",
    "    find_files_with_string,\n",
    "    hb_extract,\n",
    "    frame_timestamps,\n",
    "    find_local_hb_peaks,\n",
    "    get_camel_case,\n",
    "    write_dict_to_json,\n",
    "    P5M5DataLoader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1471333",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find_files_with_string(string=\"pantompkins1985\", file_dir=code_paths[\"repo_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e339f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# things to experiment with\n",
    "# changing highcut [20, 30]\n",
    "# changing k_nearest_intervals [8, 12, 14]\n",
    "# changing interpolation method to something more complex than linear, e.g. polynomial with order=3 (probably need to unpack dict for this **interpolation_args)\n",
    "# or just argument with string\n",
    "# can also try changing fixpeaks by height to be only the times that were changed\n",
    "# can change size of HB template too...\n",
    "# rri_anomalies thresholds\n",
    "# threshold for peak fixing\n",
    "# clean_method in fixpeaks_by_height\n",
    "# time_boundaries in fixpeaks_by_height\n",
    "# or just give option to pass clean_sig_info and raw_sig_info\n",
    "# can adapt the time_boundaries in fix_peaks_by_height based on the heart rate variability of confident intervals\n",
    "# or more outlier removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1263396",
   "metadata": {},
   "outputs": [],
   "source": [
    "version_id = 145\n",
    "data_format = \"8k\"\n",
    "sig_name = \"ieml\"\n",
    "\n",
    "hb_extract_methods = [\"temp\", \"pc\", \"critias_bp\"]\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "git_hexsha = repo.head.object.hexsha\n",
    "frame_len = 300\n",
    "hb_extract_algo_kwargs = {\n",
    "    \"max_bpm\": 200,\n",
    "    \"min_bpm\": 40,\n",
    "    \"denoiser_type\": \"null\",\n",
    "    \"thr_corr_height\": -3,\n",
    "    \"min_n_confident_peaks\": 20,\n",
    "    \"max_time_after_last_peak\": 5,\n",
    "    \"clean_method\": \"own_filt\",\n",
    "    \"highcut\": 25,\n",
    "    \"relative_peak_height_for_temp_min\": -2,\n",
    "    \"relative_peak_height_for_temp_max\": 2,\n",
    "    \"temp_time_before_peak\": 0.3,\n",
    "    \"temp_time_after_peak\": 0.3,\n",
    "    \"fix_corr_peaks_by_height\": False,\n",
    "    \"fix_interpl_peaks_by_height\": False,\n",
    "    \"relative_rri_min\": -2.5,\n",
    "    \"relative_rri_max\": 2.5,\n",
    "    \"fixpeaks_by_height_time_boundaries\": {\n",
    "        \"before_peak_clean\": 0.1,\n",
    "        \"after_peak_clean\": 0.1,\n",
    "        \"before_peak_raw\": 0.005,\n",
    "        \"after_peak_raw\": 0.005,\n",
    "    },\n",
    "    \"corr_peak_extraction_method\": \"nk_ecg_process\",\n",
    "    \"k_nearest_intervals\": 8,\n",
    "    \"n_nan_estimation_method\": \"round\",\n",
    "    \"interpolate_args\": {\"method\": \"spline\", \"order\": 2},\n",
    "    \"output_format\": \"only_final\",\n",
    "    \"debug_out_path\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb25b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hb_extract_algo_kwargs = {\n",
    "    \"max_bpm\": 200,\n",
    "    \"min_bpm\": 40,\n",
    "    \"denoiser_type\": \"null\",\n",
    "    \"thr_corr_height\": -3,\n",
    "    \"min_n_confident_peaks\": 20,\n",
    "    \"max_time_after_last_peak\": 5,\n",
    "    \"clean_method\": \"own_filt\",\n",
    "    \"highcut\": 25,\n",
    "    \"relative_peak_height_for_temp_min\": -2,\n",
    "    \"relative_peak_height_for_temp_max\": 2,\n",
    "    \"temp_time_before_peak\": 0.3,\n",
    "    \"temp_time_after_peak\": 0.3,\n",
    "    \"fix_corr_peaks_by_height\": False,\n",
    "    \"fix_interpl_peaks_by_height\": False,\n",
    "    \"relative_rri_min\": -2.5,\n",
    "    \"relative_rri_max\": 2.5,\n",
    "    \"fixpeaks_by_height_time_boundaries\": {\n",
    "        \"before_peak_clean\": 0.1,\n",
    "        \"after_peak_clean\": 0.1,\n",
    "        \"before_peak_raw\": 0.005,\n",
    "        \"after_peak_raw\": 0.005,\n",
    "    },\n",
    "    \"corr_peak_extraction_method\": \"nk_ecg_process\",\n",
    "    \"k_nearest_intervals\": 8,\n",
    "    \"n_nan_estimation_method\": \"round\",\n",
    "    #\"interpolate_args\": {\"method\": \"spline\", \"order\": 2},\n",
    "    \"interpolate_args\": {\"method\": \"akima\"},\n",
    "    \"use_rri_to_peak_time\": True,\n",
    "    \"move_average_rri_window\": 3,\n",
    "    \"output_format\": \"only_final\",\n",
    "    \"debug_out_path\": None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19fb67f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = P5M5DataLoader()\n",
    "\n",
    "all_sub_part_ids = loader.get_dataset_iterator(unsegmented=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e12f5d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('P5M5_1', 'P01', '_unsegmented'),\n",
       " ('P5M5_1', 'P03', '_unsegmented'),\n",
       " ('P5M5_1', 'P04', '_unsegmented'),\n",
       " ('P5M5_1', 'P05', '_unsegmented'),\n",
       " ('P5M5_1', 'P07', '_unsegmented'),\n",
       " ('P5M5_1', 'P08', '_unsegmented'),\n",
       " ('P5M5_1', 'P09', '_unsegmented'),\n",
       " ('P5M5_1', 'P12', '_unsegmented'),\n",
       " ('P5M5_1', 'P14', '_unsegmented'),\n",
       " ('P5M5_1', 'P16', '_unsegmented'),\n",
       " ('P5M5_1', 'P17', '_unsegmented'),\n",
       " ('P5M5_1', 'P18', '_unsegmented'),\n",
       " ('P5M5_1', 'P24', '_unsegmented'),\n",
       " ('P5M5_1', 'P25', '_unsegmented'),\n",
       " ('P5M5_1', 'P26', '_unsegmented'),\n",
       " ('P5M5_2', 'P01', '_unsegmented'),\n",
       " ('P5M5_2', 'P02', '_unsegmented'),\n",
       " ('P5M5_2', 'P03', '_unsegmented'),\n",
       " ('P5M5_2', 'P04', '_unsegmented'),\n",
       " ('P5M5_2', 'P05', '_unsegmented'),\n",
       " ('P5M5_2', 'P06', '_unsegmented'),\n",
       " ('P5M5_2', 'P07', '_unsegmented'),\n",
       " ('P5M5_2', 'P08', '_unsegmented'),\n",
       " ('P5M5_2', 'P09', '_unsegmented'),\n",
       " ('P5M5_2', 'P10', '_unsegmented'),\n",
       " ('P5M5_2', 'P11', '_unsegmented'),\n",
       " ('P5M5_2', 'P12', '_unsegmented'),\n",
       " ('P5M5_2', 'P13', '_unsegmented'),\n",
       " ('P5M5_2', 'P14', '_unsegmented'),\n",
       " ('P5M5_2', 'P15', '_unsegmented'),\n",
       " ('P5M5_3', 'P01', '_unsegmented'),\n",
       " ('P5M5_3', 'P02', '_unsegmented'),\n",
       " ('P5M5_3', 'P03', '_unsegmented'),\n",
       " ('P5M5_3', 'P04', '_unsegmented'),\n",
       " ('P5M5_3', 'P05', '_unsegmented'),\n",
       " ('P5M5_3', 'P06', '_unsegmented'),\n",
       " ('P5M5_3', 'P07', '_unsegmented'),\n",
       " ('P5M5_3', 'P08', '_unsegmented'),\n",
       " ('P5M5_3', 'P09', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P00', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P01', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P02', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P03', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P04', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P05', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P06', '_unsegmented'),\n",
       " ('P5M5_breathing', 'P07', '_unsegmented')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sub_part_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4cc9af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_out_path = pathlib.Path(loader.get_paths()[\"data_derivatives_dir\"],\"hb_annotations\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41437046",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_label, sub_id, cond_label = all_sub_part_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194b8cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_name = \"ieml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6fc2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\lib\\NeuroKit\\neurokit2\\signal\\signal_fixpeaks.py:277: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  mrrs /= th2\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\lib\\NeuroKit\\neurokit2\\signal\\signal_fixpeaks.py:277: RuntimeWarning: invalid value encountered in true_divide\n",
      "  mrrs /= th2\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:479: UserWarning: Warning: the difference between timepoints is not uniform\n",
      "  warn(\"Warning: the difference between timepoints is not uniform\")\n"
     ]
    }
   ],
   "source": [
    "for frame_len in [450, 600, 60, 90, 120]:\n",
    "    for hb_extract_method in hb_extract_methods:\n",
    "        version_id += 1\n",
    "        for dataset_label, sub_id, cond_label in all_sub_part_ids:\n",
    "\n",
    "            loader = P5M5DataLoader(dataset_label=dataset_label, sub_id=sub_id, cond_label=cond_label)\n",
    "\n",
    "            sig_info = loader.get_sig(data_format=\"8k\", sig_name=sig_name)\n",
    "\n",
    "            if \"nk\" in hb_extract_method:\n",
    "                auto_method_acronym = \"NK\"\n",
    "            else:\n",
    "                auto_method_acronym = hb_extract_method.upper()\n",
    "            name_peaks_dict = {\"zephyr_ecg\": \"R_Peak\", \"ti_ppg\": \"SP\", \"ieml\": \"S1_Peak\"}\n",
    "            label = name_peaks_dict[sig_info[\"name\"]]\n",
    "\n",
    "\n",
    "            txt_json_base_name = (\n",
    "                dataset_label\n",
    "                + \"_\"\n",
    "                + sub_id\n",
    "                + cond_label\n",
    "                + \"-\"\n",
    "                + sig_info[\"name\"]\n",
    "                + \"-Ann-Auto-\"\n",
    "                + auto_method_acronym\n",
    "                + \"-\"\n",
    "                + name_peaks_dict[sig_info[\"name\"]]\n",
    "                + \"_v\"\n",
    "                + str(version_id)\n",
    "            )\n",
    "            txt_file_name = txt_json_base_name + \".txt\"\n",
    "            json_file_name = txt_json_base_name + \".json\"\n",
    "            txt_path = str(\n",
    "                pathlib.Path(\n",
    "                    root_out_path,\n",
    "                    dataset_label,\n",
    "                    sub_id,\n",
    "                    cond_label,\n",
    "                    \"v\" + str(version_id),\n",
    "                    txt_file_name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            json_path = str(\n",
    "                pathlib.Path(\n",
    "                    root_out_path,\n",
    "                    dataset_label,\n",
    "                    sub_id,\n",
    "                    cond_label,\n",
    "                    \"v\" + str(version_id),\n",
    "                    json_file_name,\n",
    "                )\n",
    "            )\n",
    "\n",
    "            debug_out_path = str(\n",
    "                pathlib.Path(\n",
    "                    root_out_path,\n",
    "                    dataset_label,\n",
    "                    sub_id,\n",
    "                    cond_label,\n",
    "                    \"v\" + str(version_id),\n",
    "                    txt_json_base_name + \"_debug_out\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "\n",
    "            hb_extract_params = hb_extract_algo_kwargs.copy()\n",
    "            hb_extract_params[\"detector_type\"] = hb_extract_method\n",
    "            hb_extract_params[\"frame_len\"] = frame_len\n",
    "            hb_extract_params[\"validity\"] = True\n",
    "            hb_extract_params[\"version\"] = version_id\n",
    "            hb_extract_params[\"git_hexsha\"] = git_hexsha\n",
    "\n",
    "            write_dict_to_json(hb_extract_params, json_path=json_path)\n",
    "\n",
    "\n",
    "            if not pathlib.Path(txt_path).is_file():\n",
    "                sig_info[\"peak_time\"] = frame_timestamps(\n",
    "                    func=hb_extract,\n",
    "                    sig=sig_info[\"sig\"],\n",
    "                    sig_time=sig_info[\"time\"],\n",
    "                    frame_len=frame_len,\n",
    "                    sig_name=sig_info[\"name\"],\n",
    "                    method=hb_extract_method,\n",
    "                    hb_extract_algo_kwargs=hb_extract_algo_kwargs,\n",
    "                    save_file=True,\n",
    "                    txt_path=txt_path,\n",
    "                    label=label,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "910b9cc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('P5M5_1', 'P05', '_unsegmented')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_label, sub_id, cond_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89dcdf29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1), (2, 1), (3, 1), (4, 1), (4, 2), (5, 1), (6, 1)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sub_part_ids = P5_StressDataLoader().get_all_sub_part_ids()\n",
    "all_sub_part_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0a0b992",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "all_sub_part_ids = P5_StressDataLoader().get_all_sub_part_ids()\n",
    "version_id = 158\n",
    "data_format = \"DB8k\"\n",
    "# sig_name = \"zephyr_ecg\"\n",
    "sig_name = \"ieml\"\n",
    "# hb_extract_method = \"critias_bp\"\n",
    "\n",
    "# frame_len = 30\n",
    "# frame_len = 180\n",
    "# frame_len = 180\n",
    "ecg_process_methods = [\n",
    "    \"neurokit\",\n",
    "    \"pantompkins1985\",\n",
    "    \"hamilton2002\",\n",
    "    \"christov2004\",\n",
    "    \"engzeemod2012\",\n",
    "    \"elgendi2010\",\n",
    "    \"kalidas2017\",\n",
    "]\n",
    "hb_extract_method = \"pc\"\n",
    "hb_extract_method = \"nk_ppg_elgendi\"\n",
    "hb_extract_method = \"temp\"\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "git_hexsha = repo.head.object.hexsha\n",
    "frame_len = 300\n",
    "\n",
    "\n",
    "\n",
    "root_out_path = pathlib.Path(\"Z:\\Shared\\Documents\\RD\\RD2\\_AudioRD\\datasets\\Biosignals\\CritiasStress\\data_derivatives\\hb_annotations\")\n",
    "version_id += 1\n",
    "for sub_id, part_id in all_sub_part_ids:\n",
    "\n",
    "    loader = P5_StressDataLoader(sub_id=sub_id, part_id=part_id)\n",
    "    sig_info = loader.get_sig(data_format=data_format, sig_name=sig_name)\n",
    "\n",
    "    if \"nk\" in hb_extract_method:\n",
    "        auto_method_acronym = \"NK\"\n",
    "    else:\n",
    "        auto_method_acronym = hb_extract_method.upper()\n",
    "    name_peaks_dict = {\"zephyr_ecg\": \"R_Peak\", \"ti_ppg\": \"SP\", \"ieml\": \"S1_Peak\"}\n",
    "    label = name_peaks_dict[sig_info[\"name\"]]\n",
    "\n",
    "\n",
    "    txt_json_base_name = (\n",
    "        \"P5_Stress-\"\n",
    "        + loader.sub_label\n",
    "        + \"_\"\n",
    "        + str(loader.part_id)\n",
    "        + \"-\"\n",
    "        + sig_info[\"name\"]\n",
    "        + \"-Ann-Auto-\"\n",
    "        + auto_method_acronym\n",
    "        + \"-\"\n",
    "        + name_peaks_dict[sig_info[\"name\"]]\n",
    "        + \"_v\"\n",
    "        + str(version_id)\n",
    "    )\n",
    "    txt_file_name = txt_json_base_name + \".txt\"\n",
    "    json_file_name = txt_json_base_name + \".json\"\n",
    "    txt_path = str(\n",
    "        pathlib.Path(\n",
    "            loader.set_paths(data_format=\"hb_annotations\")[\"sub_data_dir\"],\n",
    "            \"v\" + str(version_id),\n",
    "            txt_file_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    json_path = str(\n",
    "        pathlib.Path(\n",
    "            loader.set_paths(data_format=\"hb_annotations\")[\"sub_data_dir\"],\n",
    "            \"v\" + str(version_id),\n",
    "            json_file_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    debug_out_path = str(\n",
    "        pathlib.Path(\n",
    "            loader.set_paths(data_format=\"hb_annotations\")[\"sub_data_dir\"],\n",
    "            \"v\" + str(version_id),\n",
    "            txt_json_base_name + \"_debug_out\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    hb_extract_algo_kwargs = {\n",
    "    \"max_bpm\": 200,\n",
    "    \"min_bpm\": 40,\n",
    "    \"denoiser_type\": \"null\",\n",
    "    \"thr_corr_height\": -3,\n",
    "    \"min_n_confident_peaks\": 20,\n",
    "    \"max_time_after_last_peak\": 5,\n",
    "    \"clean_method\": \"own_filt\",\n",
    "    \"highcut\": 25,\n",
    "    \"relative_peak_height_for_temp_min\": -2,\n",
    "    \"relative_peak_height_for_temp_max\": 2,\n",
    "    \"temp_time_before_peak\": 0.3,\n",
    "    \"temp_time_after_peak\": 0.3,\n",
    "    \"fix_corr_peaks_by_height\": False,\n",
    "    \"fix_interpl_peaks_by_height\": False,\n",
    "    \"relative_rri_min\": -2.5,\n",
    "    \"relative_rri_max\": 2.5,\n",
    "    \"fixpeaks_by_height_time_boundaries\": {\n",
    "        \"before_peak_clean\": 0.1,\n",
    "        \"after_peak_clean\": 0.1,\n",
    "        \"before_peak_raw\": 0.005,\n",
    "        \"after_peak_raw\": 0.005,\n",
    "    },\n",
    "    \"corr_peak_extraction_method\": \"nk_ecg_process\",\n",
    "    \"k_nearest_intervals\": 8,\n",
    "    \"n_nan_estimation_method\": \"round\",\n",
    "    #\"interpolate_args\": {\"method\": \"spline\", \"order\": 2},\n",
    "    \"move_average_rri_window\": None,\n",
    "    \"interpolate_args\": {\"method\": \"akima\"},\n",
    "    \"use_rri_to_peak_time\": True,\n",
    "    \"find_anomalies_threshold\": None,\n",
    "    \"output_format\": \"debug\",\n",
    "    \"debug_out_path\": debug_out_path,\n",
    "    }\n",
    "    hb_extract_params = hb_extract_algo_kwargs.copy()\n",
    "    hb_extract_params[\"detector_type\"] = hb_extract_method\n",
    "    hb_extract_params[\"frame_len\"] = frame_len\n",
    "    hb_extract_params[\"validity\"] = True\n",
    "    hb_extract_params[\"version\"] = version_id\n",
    "    hb_extract_params[\"git_hexsha\"] = git_hexsha\n",
    "\n",
    "    write_dict_to_json(hb_extract_params, json_path=json_path)\n",
    "\n",
    "\n",
    "    if not pathlib.Path(txt_path).is_file():\n",
    "        sig_info[\"peak_time\"] = frame_timestamps(\n",
    "            func=hb_extract,\n",
    "            sig=sig_info[\"sig\"],\n",
    "            sig_time=sig_info[\"time\"],\n",
    "            frame_len=frame_len,\n",
    "            sig_name=sig_info[\"name\"],\n",
    "            method=hb_extract_method,\n",
    "            hb_extract_algo_kwargs=hb_extract_algo_kwargs,\n",
    "            save_file=True,\n",
    "            txt_path=txt_path,\n",
    "            label=label,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d24799b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:991: UserWarning: Warning: Z:Shared\\Documents\\RD\\RD2\\_AudioRD\\datasets\\Biosignals\\CritiasStress\\data_derivatives\\hb_annotations\\P01\\v158\\P5_Stress-P01_1-ieml-Ann-Auto-TEMP-S1_Peak_v158.json already exists.\n",
      "  warn(\"Warning: \" + json_path + \" already exists.\")\n",
      "C:\\Users\\dbenesch\\eers\\git\\p5-stress-classifier\\src\\stresspred\\preprocessing.py:991: UserWarning: Warning: Z:Shared\\Documents\\RD\\RD2\\_AudioRD\\datasets\\Biosignals\\CritiasStress\\data_derivatives\\hb_annotations\\P02\\v158\\P5_Stress-P02_1-ieml-Ann-Auto-TEMP-S1_Peak_v158.json already exists.\n",
      "  warn(\"Warning: \" + json_path + \" already exists.\")\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\dbenesch\\AppData\\Roaming\\Python\\Python39\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "all_sub_part_ids = P5_StressDataLoader().get_all_sub_part_ids()\n",
    "version_id = 157\n",
    "data_format = \"DB8k\"\n",
    "# sig_name = \"zephyr_ecg\"\n",
    "sig_name = \"ieml\"\n",
    "# hb_extract_method = \"critias_bp\"\n",
    "\n",
    "# frame_len = 30\n",
    "# frame_len = 180\n",
    "# frame_len = 180\n",
    "ecg_process_methods = [\n",
    "    \"neurokit\",\n",
    "    \"pantompkins1985\",\n",
    "    \"hamilton2002\",\n",
    "    \"christov2004\",\n",
    "    \"engzeemod2012\",\n",
    "    \"elgendi2010\",\n",
    "    \"kalidas2017\",\n",
    "]\n",
    "hb_extract_method = \"pc\"\n",
    "hb_extract_method = \"nk_ppg_elgendi\"\n",
    "hb_extract_method = \"temp\"\n",
    "repo = git.Repo(search_parent_directories=True)\n",
    "git_hexsha = repo.head.object.hexsha\n",
    "frame_len = 300\n",
    "\n",
    "\n",
    "\n",
    "root_out_path = pathlib.Path(\"Z:\\Shared\\Documents\\RD\\RD2\\_AudioRD\\datasets\\Biosignals\\CritiasStress\\data_derivatives\\hb_annotations\")\n",
    "version_id += 1\n",
    "for sub_id, part_id in all_sub_part_ids:\n",
    "\n",
    "    loader = P5_StressDataLoader(sub_id=sub_id, part_id=part_id)\n",
    "    sig_info = loader.get_sig(data_format=data_format, sig_name=sig_name)\n",
    "\n",
    "    if \"nk\" in hb_extract_method:\n",
    "        auto_method_acronym = \"NK\"\n",
    "    else:\n",
    "        auto_method_acronym = hb_extract_method.upper()\n",
    "    name_peaks_dict = {\"zephyr_ecg\": \"R_Peak\", \"ti_ppg\": \"SP\", \"ieml\": \"S1_Peak\"}\n",
    "    label = name_peaks_dict[sig_info[\"name\"]]\n",
    "\n",
    "\n",
    "    txt_json_base_name = (\n",
    "        \"P5_Stress-\"\n",
    "        + loader.sub_label\n",
    "        + \"_\"\n",
    "        + str(loader.part_id)\n",
    "        + \"-\"\n",
    "        + sig_info[\"name\"]\n",
    "        + \"-Ann-Auto-\"\n",
    "        + auto_method_acronym\n",
    "        + \"-\"\n",
    "        + name_peaks_dict[sig_info[\"name\"]]\n",
    "        + \"_v\"\n",
    "        + str(version_id)\n",
    "    )\n",
    "    txt_file_name = txt_json_base_name + \".txt\"\n",
    "    json_file_name = txt_json_base_name + \".json\"\n",
    "    txt_path = str(\n",
    "        pathlib.Path(\n",
    "            loader.set_paths(data_format=\"hb_annotations\")[\"sub_data_dir\"],\n",
    "            \"v\" + str(version_id),\n",
    "            txt_file_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    json_path = str(\n",
    "        pathlib.Path(\n",
    "            loader.set_paths(data_format=\"hb_annotations\")[\"sub_data_dir\"],\n",
    "            \"v\" + str(version_id),\n",
    "            json_file_name,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    debug_out_path = str(\n",
    "        pathlib.Path(\n",
    "            loader.set_paths(data_format=\"hb_annotations\")[\"sub_data_dir\"],\n",
    "            \"v\" + str(version_id),\n",
    "            txt_json_base_name + \"_debug_out\",\n",
    "        )\n",
    "    )\n",
    "\n",
    "    hb_extract_algo_kwargs = {\n",
    "    \"max_bpm\": 200,\n",
    "    \"min_bpm\": 40,\n",
    "    \"denoiser_type\": \"null\",\n",
    "    \"thr_corr_height\": -3,\n",
    "    \"min_n_confident_peaks\": 20,\n",
    "    \"max_time_after_last_peak\": 5,\n",
    "    \"clean_method\": \"own_filt\",\n",
    "    \"highcut\": 25,\n",
    "    \"relative_peak_height_for_temp_min\": -2,\n",
    "    \"relative_peak_height_for_temp_max\": 2,\n",
    "    \"temp_time_before_peak\": 0.3,\n",
    "    \"temp_time_after_peak\": 0.3,\n",
    "    \"fix_corr_peaks_by_height\": False,\n",
    "    \"fix_interpl_peaks_by_height\": False,\n",
    "    \"relative_rri_min\": -2.5,\n",
    "    \"relative_rri_max\": 2.5,\n",
    "    \"fixpeaks_by_height_time_boundaries\": {\n",
    "        \"before_peak_clean\": 0.1,\n",
    "        \"after_peak_clean\": 0.1,\n",
    "        \"before_peak_raw\": 0.005,\n",
    "        \"after_peak_raw\": 0.005,\n",
    "    },\n",
    "    \"corr_peak_extraction_method\": \"nk_ecg_process\",\n",
    "    \"k_nearest_intervals\": 8,\n",
    "    \"n_nan_estimation_method\": \"round\",\n",
    "    #\"interpolate_args\": {\"method\": \"spline\", \"order\": 2},\n",
    "    \"move_average_rri_window\": None,\n",
    "    \"interpolate_args\": {\"method\": \"akima\"},\n",
    "    \"use_rri_to_peak_time\": True,\n",
    "    \"find_anomalies_threshold\": None,\n",
    "    \"output_format\": \"only_final\",\n",
    "    \"debug_out_path\": None,\n",
    "    }\n",
    "    hb_extract_params = hb_extract_algo_kwargs.copy()\n",
    "    hb_extract_params[\"detector_type\"] = hb_extract_method\n",
    "    hb_extract_params[\"frame_len\"] = frame_len\n",
    "    hb_extract_params[\"validity\"] = True\n",
    "    hb_extract_params[\"version\"] = version_id\n",
    "    hb_extract_params[\"git_hexsha\"] = git_hexsha\n",
    "\n",
    "    write_dict_to_json(hb_extract_params, json_path=json_path)\n",
    "\n",
    "\n",
    "    if not pathlib.Path(txt_path).is_file():\n",
    "        sig_info[\"peak_time\"] = frame_timestamps(\n",
    "            func=hb_extract,\n",
    "            sig=sig_info[\"sig\"],\n",
    "            sig_time=sig_info[\"time\"],\n",
    "            frame_len=frame_len,\n",
    "            sig_name=sig_info[\"name\"],\n",
    "            method=hb_extract_method,\n",
    "            hb_extract_algo_kwargs=hb_extract_algo_kwargs,\n",
    "            save_file=True,\n",
    "            txt_path=txt_path,\n",
    "            label=label,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484120c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader.set_paths(data_format=\"hb_annotations\")[\"sub_data_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39dc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.append(np.array([1, 2, 3]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417aa485",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_info[\"peak_time\"] = frame_timestamps(\n",
    "    func=hb_extract,\n",
    "    sig=sig_info[\"sig\"],\n",
    "    sig_time=sig_info[\"time\"],\n",
    "    frame_len=frame_len,\n",
    "    sig_name=sig_info[\"name\"],\n",
    "    save_file=True,\n",
    "    txt_path=txt_path,\n",
    "    label=label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efa36eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sub_part_ids = P5_StressDataLoader().get_all_sub_part_ids()\n",
    "for sub_id, part_id in all_sub_part_ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a752030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_info[\"peak_time\"] = frame_timestamps(\n",
    "    func=hb_extract,\n",
    "    sig=sig_info[\"sig\"],\n",
    "    sig_time=sig_info[\"time\"],\n",
    "    frame_len=frame_len,\n",
    "    sig_name=sig_info[\"name\"],\n",
    "    save_file=True,\n",
    "    txt_path=txt_path,\n",
    "    label=label,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3fb87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function stresspred.preprocessing.timestamps_to_audacity_txt(timestamp, txt_path='out.txt', label='timestamp', save=True, rewrite=False)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps_to_audacity_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part_id = 2\n",
    "part_id = 1\n",
    "# for sub_id in [4]:\n",
    "sig_names = [\"zephyr_ecg\", \"ti_ppg\", \"ieml\"]\n",
    "sig_names = [\"zephyr_ecg\", \"ti_ppg\"]\n",
    "sig_names = [\"ieml\"]\n",
    "for sub_id in [5]:\n",
    "    for sig_name in sig_names:\n",
    "        data_format = \"DB8k\"\n",
    "        loader = P5_StressDataLoader(sub_id=sub_id, part_id=part_id)\n",
    "        sig_info = loader.get_sig(data_format=data_format, sig_name=sig_name)\n",
    "        data_format_paths = loader.get_paths(data_format=data_format)\n",
    "        df_for_class = loader.get_timestamps_df_for_class()\n",
    "        timestamps_to_audacity_txt(\n",
    "            df_for_class.loc[:, [\"start_time\", \"end_time\"]].values,\n",
    "            #str(data_format_paths[\"zephyr_ecg_sig\"].stem) + \"_task\" + \".txt\",\n",
    "            (\"P5_Stress-\"\n",
    "            + loader.sub_label\n",
    "            + \"_\"\n",
    "            + str(loader.part_id)\n",
    "            + \"-\"\n",
    "            + get_camel_case(sig_info[\"name\"], first_upper=True)\n",
    "            + \"-Ann-Manual-LT-Task.txt\"),\n",
    "            label=\"to_label\",\n",
    "            rewrite=True\n",
    "        )\n",
    "        sig_info[\"peak_time\"] = hb_extract(sig=sig_info[\"sig\"], sig_time=sig_info[\"time\"], sig_name=sig_info[\"name\"])\n",
    "        name_peaks_dict = {\"zephyr_ecg\": \"R_Peak\", \"ti_ppg\": \"SP\", \"ieml\": \"S1_Peak\"}\n",
    "        if sig_name == \"ieml\":\n",
    "            auto_method_acronym = \"PC\"\n",
    "        else:\n",
    "            auto_method_acronym = \"NK\"\n",
    "        timestamps_to_audacity_txt(\n",
    "            sig_info[\"peak_time\"],\n",
    "            # str(data_format_paths[sig_info[\"name\"] + \"_sig\"].stem) + \"_peaks_auto\" + \".txt\",\n",
    "            \"P5_Stress-\"\n",
    "            + loader.sub_label\n",
    "            + \"_\"\n",
    "            + str(loader.part_id)\n",
    "            + \"-\"\n",
    "            + get_camel_case(sig_info[\"name\"], first_upper=True)\n",
    "            + \"-Ann-Auto-\"\n",
    "            + auto_method_acronym\n",
    "            + \"-\"\n",
    "            + name_peaks_dict[sig_info[\"name\"]]\n",
    "            + \".txt\",\n",
    "            label=name_peaks_dict[sig_info[\"name\"]],\n",
    "            rewrite=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cc6d0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': ['rest_task_mentalNoise', 'rest_task_mental', 'rest_task_cpt', 'rest_task_speechBaseline', 'rest_task_speechStressed', 'task_mentalNoise', 'task_mental', 'task_cpt', 'task_speechBaseline', 'task_speechStressed'], 'start_time': array([ 215.84375925,  873.25803475, 1537.942431  , 2206.231749  ,\n",
      "       2879.155857  ,  508.9490462 , 1176.175937  , 1834.999488  ,\n",
      "       2525.009788  , 3170.219649  ]), 'end_time': array([ 395.84375925, 1053.25803475, 1717.942431  , 2386.231749  ,\n",
      "       3059.155857  ,  688.9490462 , 1356.175937  , 2014.999488  ,\n",
      "       2705.009788  , 3350.219649  ])}\n",
      "{'label': ['rest_task_mentalNoise', 'rest_task_mental', 'rest_task_cpt', 'rest_task_speechBaseline', 'rest_task_speechStressed', 'task_mentalNoise', 'task_mental', 'task_cpt', 'task_speechBaseline', 'task_speechStressed'], 'start_time': array([ 215.84375925,  873.25803475, 1537.942431  , 2206.231749  ,\n",
      "       2879.155857  ,  508.9490462 , 1176.175937  , 1834.999488  ,\n",
      "       2525.009788  , 3170.219649  ]), 'end_time': array([ 395.84375925, 1053.25803475, 1717.942431  , 2386.231749  ,\n",
      "       3059.155857  ,  688.9490462 , 1356.175937  , 2014.999488  ,\n",
      "       2705.009788  , 3350.219649  ])}\n"
     ]
    }
   ],
   "source": [
    "# part_id = 2\n",
    "part_id = 1\n",
    "# for sub_id in [4]:\n",
    "sig_names = [\"zephyr_ecg\", \"ti_ppg\", \"ieml\"]\n",
    "sig_names = [\"ieml\"]\n",
    "sig_names = [\"zephyr_ecg\", \"ti_ppg\"]\n",
    "for sub_id in [5]:\n",
    "    for sig_name in sig_names:\n",
    "        data_format = \"DB8k\"\n",
    "        loader = P5_StressDataLoader(sub_id=sub_id, part_id=part_id)\n",
    "        sig_info = loader.get_sig(data_format=data_format, sig_name=sig_name)\n",
    "        data_format_paths = loader.get_paths(data_format=data_format)\n",
    "        df_for_class = loader.get_timestamps_df_for_class()\n",
    "        timestamps_to_audacity_txt(\n",
    "            df_for_class.loc[:, [\"start_time\", \"end_time\"]].values,\n",
    "            #str(data_format_paths[\"zephyr_ecg_sig\"].stem) + \"_task\" + \".txt\",\n",
    "            (\"P5_Stress-\"\n",
    "            + loader.sub_label\n",
    "            + \"_\"\n",
    "            + str(loader.part_id)\n",
    "            + \"-\"\n",
    "            + get_camel_case(sig_info[\"name\"], first_upper=True)\n",
    "            + \"-Ann-Manual-LT-Task.txt\"),\n",
    "            label=\"to_label\",\n",
    "            rewrite=True\n",
    "        )\n",
    "        sig_info[\"peak_time\"] = hb_extract(sig=sig_info[\"sig\"], sig_time=sig_info[\"time\"], sig_name=sig_info[\"name\"])\n",
    "        name_peaks_dict = {\"zephyr_ecg\": \"R_Peak\", \"ti_ppg\": \"SP\", \"ieml\": \"S1_Peak\"}\n",
    "        timestamps_to_audacity_txt(\n",
    "            sig_info[\"peak_time\"],\n",
    "            # str(data_format_paths[sig_info[\"name\"] + \"_sig\"].stem) + \"_peaks_auto\" + \".txt\",\n",
    "            \"P5_Stress-\"\n",
    "            + loader.sub_label\n",
    "            + \"_\"\n",
    "            + str(loader.part_id)\n",
    "            + \"-\"\n",
    "            + get_camel_case(sig_info[\"name\"], first_upper=True)\n",
    "            + \"-Ann-Auto-NK-\"\n",
    "            + name_peaks_dict[sig_info[\"name\"]]\n",
    "            + \".txt\",\n",
    "            label=name_peaks_dict[sig_info[\"name\"]],\n",
    "            rewrite=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7bdcc2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.71891149e-01, 1.32683435e+00, 2.07174135e+00, ...,\n",
       "       3.55360135e+03, 3.55471021e+03, 3.55554211e+03])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig_info[\"peak_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1c15620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(hb_extract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00904da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_to_audacity_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e9586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sig_info[\"cor_peak_time\"] = find_local_hb_peaks(sig_info[\"peak_time\"], \n",
    "                     sig=sig_info[\"sig\"], \n",
    "                     sig_time=sig_info[\"time\"], \n",
    "                     sampling_rate=sig_info[\"sampling_rate\"], \n",
    "                     check_height_outlier=True)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7461b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be two outputs of TEMP: peaks we are confident in, and complete interpolated peak times\n",
    "# parameters I should try changing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cee004e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"ti_ppg\"\n",
    "s = re.sub(r\"(_|-)+\", \" \", s).title().replace(\" \", \"\")\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf9da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "P5_Stress-P01-TiPpg-Ann-Manual-LT-Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0f3ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c5fbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "P5_Stress-P01-TiPpg-Ann-Auto-NK-SP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
